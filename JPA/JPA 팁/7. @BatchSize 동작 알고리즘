








우리가 @BatchSize의 size값을 지정하면 그 값만큼 IN에 id가 무조건 들어갈 거라고 생각할 것이다.

하지만 그렇지 않다.

이건 @BatchSize의 최적화 알고리즘에 따라 다르게 설정이 가능한데, default는 LEGACY방식을 사용한다.


먼저, 이 내용을 제대로 이해하려면 Statement와 PreparedStatement의 차이점을 알아야 한다.

# 자세한 건 https://webstone.tistory.com/56 참조

이 내용을 여기에 모두 적기에는 좀 귀찮으니 간략히만 설명하면

Statement는 executeQuery() 나 executeUpdate() 를 실행하는 시점에 파라미터로 SQL문을 전달하는데,

이렇게 SQL문을 수행할 때마다 매번 컴파일이 일어난다는 단점이 있다.


하지만 PreparedStatement은 미리 컴파일을 해 놓고 캐시에 저장해 놓는다. 

그래서 수행 속도가 빠르고 재사용성이 높다.

만약 동일한 쿼리를 반복적으로 수행한다면 PreparedStatement가 DB에 훨씬 적은 부하를 준다.


위를 보면 알겠지만 BatchSize를 사용할 때에는 PreparedStatement를 사용하는 게 훨씬 좋다.

@BatchSize의 size값은 IN에 들어갈 id값의 개수이기 때문에 PreparedStatement로 IN에 '?'만 size값만큼 넣어 두면 되기 때문이다.

근데, 여기서 문제는 조회하는 데이터의 수가 딱딱 size만큼 맞아 떨어지지 않는다는 것이다.

예를 들어 BatchSize를 100으로 잡아 놨는데 조회되는 IN에 들어갈 Entity id의 수가 총 50개 밖에 안 된다면 어떡할까?

PreparedStatement는 미리 SQL을 컴파일 해 놓기 때문에 변화를 줄 수 없다.

이미 지정된 '?'에 값이 들어오면 그대로 실행만할 수 있는 것이다.


그럼 위의 문제를 해결하기 위해서는 BatchSize의 size값만큼의 PreparedStatement를 준비하는 것이다.

예를 들어 100이라면 '?'개수가 1~100개인 PreparedStatement를 준비하는 것이다.

그럼 총 100개의 PreparedStatement가 필요하다.

그럼 이제 50개를 조회하든 10개를 조회하든 준비된 PreparedStatement가 있으니 그걸 사용할 수 있을 것이다.

근데 이게 과연 괜찮은 방법일까?


PreparedStatement가 무조건적으로 좋아 보이지만 모든 쿼리를 PreparedStatement로 만들어서

너무 많은 PreparedStatement가 캐싱되면 반대로 성능이 떨어질 수 있고, 

나중에 정작 진짜로 PreparedStatement로 사용하기에 좋은 또는 중요한 쿼리들에서 동작이 제대로 안 먹을 수도 있다고 한다.

# 이 부분은 진짠지 모르겠음

하여튼 이러한 문제 때문에 PreparedStatement가 과하게 남용되는 것은 좋지 않다.

상식적으로 생각해 봐도 BatchSize가 1000일 때에는 PreparedStatement가 1000개인데, 뭔가 문제가 생길 것 같지 않은가?


그래서 Hibernate는 내부적으로 알고리즘을 짜 놓았다.

PreparedStatement를 size / 2로 계속 나누어 가면서 PreparedStatement를 준비해 놓는 방식을 취한 것이다.

예를 들어 size가 100이면 '?'의 개수가 100,50,25,12,1~10 이렇게 PreparedStatement를 준비해 놓고 사용하는 것이다.

기본적으로 1~10까지는 반드시 만들어 둔다. 그래야 1의 자리수 단위의 Entity수에 맞춰서 조회가 가능하기 때문이다.


이렇게 만들어 놓은 쿼리는 이런 식으로 동작한다.

위의 상태에서 우리가 130개의 Entity를 @BatchSize로 조회한다고 해 보자.

그럼 먼저, '?'가 100개인 PreparedStatement를 사용해서 100개를 조회하고 나머지 30개는

25개짜리를 사용하고 5개짜리를 사용해서 개수를 맞춘다.

즉, 우리가 @BatchSize의 size값을 100으로 해 놓았다고 130개를 조회할 때 두 번의 쿼리로 다 조회되는 게 아니라 3번의 쿼리가 나가는 것이다.

이는 내부적으로 PreparedStatement의 최적화 알고리즘에 의한 현상이니 나중에 쿼리가 예상보다 많이 나간다고 이상해 하지 말자.


위의 방식은 LEGACY방식으로 동작할 때의 최적화 방식이다.

이 외에도 padded, dynamic 방식이 있다.

padded는 그냥 더 큰 PreparedStatement를 사용하고 나머지 '?'부분을 

기존의 id들을 다시 반복해 넣어서 같은 데이터를 조회하게 만드는 형태로 동작하는 듯 하다.

즉, 쿼리는 최대 @BatchSize보다 크지 않은 이상 무조건 한 번에 처리할 수 있다는 장점이 있다.

때에 따라서는 괜찮을 지도 모르겠다.

dynamic은 우리가 바라던, PreparedStatement를 size만큼 만들어 두고 사용하는 전략이다.

성능상 문제가 있기 때문에 권장하지는 않는다고 한다.


하여튼 이런 식으로 @BatchSize가 동작하니 이를 유의하고 쿼리가 나가는 것을 인지하길 바란다.

