





JAVA가 나왔을 당시, 기존 C언어 하고는 꽤나 다른 실행 과정을 가졌다.


c언어의 실행과정


~.c(.c파일) -> 컴파일러 -> 어셈블리어 -> 어셈블러 -> 기계어 -> 링커 -> EXE


C언어의 실행 과정은 결국 컴퓨터(OS)가 알아 들을 수 있게 하기 위해 기계어를 번역하는 과정이다. 




하지만 Java의 경우 


Java는 java컴파일러가 컴파일한 .Class파일을 가지고 JVM이 실행까지의 과정을 담당한다.



java프로그램이 실행되는 과정을 간략하게 설명하면


1. 프로그램이 실행되면 JVM은 OS로부터 이 프로그램이 필요로 하는 메모리를 할당받는다.

JVM은 이 메모리를 용도에 따라 여러 영역으로 나누어 관리한다.


2. 자바 컴파일러(javac)가 자바 소스코드(.java)를 읽어들여 자바 바이트코드(.class)로 변환시킨다.


3. Class Loader를 통해 class파일들을 JVM으로 로딩한다.


4. 로딩된 class파일들은 Execution engine을 통해 해석된다.


5. 해석된 바이트코드는 Runtime Data Areas 에 배치되어 실질적인 수행이 이루어지게 된다.

이러한 실행과정 속에서 JVM은 필요에 따라 Thread Synchronization과 GC같은 관리작업을 수행한다.



먼저 JVM이 동작하기 위해서는 java로 짠 소스코드가 JVM에서 동작할 수 있는 형태인 .class 파일로 컴파일 되어야 한다.


자바의 컴파일 과정은 총 4가지에서 5가지의 과정이 있다. 

어휘 분석 -> 구문 분석 -> 의미 분석 -> 중간 코드 생성 후 최적화

java 뿐만 아니라 다른 언어에서도 이런 비슷한 원리로 컴파일 되기도 한다. 

공통적인 내용이 많으니 하나하나 알아 보도록 하자.




1. 어휘 분석


컴파일러의 첫 번째 단계는 소스 코드를 정규 문법(regular grammar)에 따라 토큰(token)으로 분류하는 어휘 분석 = 스캐닝(scanning)이다. 

정규 문법은 컴파일러의 어휘 분석 단계에서 프로그램을 구성하고 있는 토큰의 구조를 정의하는데 사용한다.



토큰(Token) : 문법에 있는 터미널 기호들로 구성된 문법적으로 의미 있는 최소 단위


일반적인 프로그래밍 언어에서 사용하는 토큰들의 예시

Special form - language designer

1. 지정어(Keyword) --- for, if, int 등의 언어에 이미 정의된 단어

2. 연산자 기호(Operator symbol) --- +, -, *, /, <, =, ++ 등의 연산기호

3. 구분자(Delimiter) --- ;, ,, (, ), [, ] 등 단어와 단어의 구분하거나 문장과 문장들을 구분


General form - programmer

4. 식별자(identifier) --- abc, b12, sum, 등 프로그래머가 정의하는 변수

5. 상수(constant) --- 526, 3.0, 0.1234e-10, 'string' 등 실수형, 정수형, 문자형 상수



패턴(Pattern) : 토큰을 서술하는 규칙들

토큰을 식별하기 위한 정해 놓은 규칙이라고 볼 수 있다.

예를 들면 변수를 선언할 때에 첫 문자가 영어나 '_'이어야 하고 

그 뒤로는 영어 숫자 '_'를 사용할 수 있다는 이 규칙이 원래 변수라는 토큰을 구분하기 위한 패턴인 것이다.

https://untitledtblog.tistory.com/11?category=670012

사이트에 패턴의 원리에 대해 잘 나타나 있다.



렉심(Lexeme) : 패턴에 의해 매칭된 문자열


예를 들어, "Lexical analysis is the first step of compiler"라는 문장에서 

'L', 'e', 'x', 'i', 'c', 'a', 'l'을 따로 놓으면 어떠한 의미도 없지만 

"Lexical"이라는 하나의 조각으로 보면 의미를 갖게 된다. 

어휘 분석 단계에서 검출되는 의미 있는 조각을 어휘 항목(lexeme)이라고 하며

어휘 분석기는 소스 코드에서 이러한 어휘 항목을 검출하여 토큰을 생성한다.


어휘 분석은 국어를 예로 들면 이해하기 쉽다.

국어에서의 단어,품사,규칙을 생각하면 편하다 '엄마는 밥을 먹는다'라는 문장에서 '엄' 과 '마' 는 각각 하나의 문자지만 

모이면 '엄마'라는 뜻을 가진 단어가 된다. 렉심은 국에에서의 단어를 말하는 것이다. 

그리고 이 '엄마'라는 단어는 국어에서 명사이다. 

이렇게 그 단어가 어떤 역할인 지를 나눈 것이 품사, 어휘 분석에서는 '토큰'이다.

그리고 어휘 분석기는 품사(토큰)의 단어(렉심)가 국어사전에 그 품사 형태의 단어가 있는 지를 확인한다.

만약 없다면 오류를 반환하는 것이다. '먹는다'라는 단어를 '뭭눈돠'라고 쓰면 오류가 발생하는 것이다.

사전에 없는 단어인 지 또는 패턴(규칙)에 어긋나게 작성된 품사인 지를 따져 오류를 발생시킨다.


'는','을' 과 같은 단어는 조사이다. 우리는 이런 '는','을'은 조사라고 정해 놓았다. 

또 '먹는다'는 행위를 나타내는 말이니 동사이다. 이런 품사(토큰)를 알아볼 수 있는 규칙이 어휘 분석에서 패턴인 것이다.

이런 규칙을 토대로 이게 명사인 지 목적어인 지 동사인 지 알 수 있듯이 패턴은 그런 규칙을 통해

각 렉심(단어)가 어떤 품사(토큰)인 지 해석할 수 있다.



하여튼 어휘 분석 단계에서는 위와 같이 얻어낸 어휘들을 토대로 하나의 '스트림'을 만든다.

스트림(stream)이란 일반적으로 데이터,패킷,비트와 같은 일련의 연속성을 갖는 흐름을 의미한다.

c언어 공부할 때 배웠던 버퍼를 생각하면 편하다.

우리가 키보드로 입력을 하면 그 데이터들은 일련의 데이터 형식으로 입력 버퍼에 저장된다.

그리고 출력될 때에는 저장된 순서대로 출력될 것이다.

버퍼는 데이터를 입출력 순서에 의해서 순차적으로 처리한 것이다.

이러한 순차적으로 처리되는 데이터 열처럼 일련의 연속성을 갖는 흐름을 스트림이라고 한다.

테트리스 마냥 옆에 순서가 있는 블록들 같은 느낌이다.

조금 말이 모호하니 쉽게 생각하면 그냥 통로가 하나 밖에 없는 데이터 나열 방식이라고 보면 된다.


그리고 이렇게 어휘들로 만들어진 스트림을 만드는 과정까지가 어휘 분석 단계이다.





2. 구문 분석


어휘 분석 단계에서 나온 토큰 스트림을 가지고 문법에 맞는지 확인한다. 

여기서 에러가 발생하면 바로 우리가 잘 아는 Syntax Error가 발생합니다.


문장의 구조가 문법적으로 옳은 지를 확인하는 것. 구문 분석 단계는 국어에서 문법을 따지는 단계라고 볼 수 있다.


"엄마는 밥을 먹는" 이라는 문장이 있다고 해 보자.

어휘 분석 단계에서 문제가 없다. '엄마','는','밥','을','먹는' 으로 잘 구분했을 것이다.

근데 이것들이 어휘 분석에서 스트림으로 만들어 지고 구문 분석 단계로 넘어 오면 문제가 생긴다.

바로 이 문장이 아직 완성되지 않았음을 발견하는 것이다. '먹는'이라는 단어의 뒤에 '다'가 빠졌다는 걸 이해한다.

명령어로 따지면 ';'이 빠진 것이다.



좀 더 구체적인 구조 분석의 원리를 알아 보면


구조 분석(Syntax analysis)은 문장이 들어왔을 때 문법 형식에 맞도록 구조를 분석하는 과정이다. 

스캐너에 의해 생성된 토큰을 입력으로 받아 주어진 문법에 맞는지를 검사하고

문법에 맞으면 파스 트리를 생성하고 맞지 않으면 에러를 내는 단계

구조 분석에 사용되는 알고리즘은 파서(Parser)이다.


파서 알고리즘은 두 가지 속성을 가지고 있다. 


첫 번째 속성은 방향성(Directionality)이다. 

이 방향성에 따라서 Top-down 방식으로 분석할 지, Bottom-up 방식으로 분석할 지를 결정하게 된다. 


두 번째 속성은 탐색 전략(Search strategy)이다. 

이 속성은 트리를 옆으로 탐색할 것인지 아래쪽으로 파고들 것인지를 결정하게 된다. 

이 두 특성에 따라 파서의 알고리즘이 달라지게 된다.


여기까지만 일단은 이해하자 너무 어려운 내용이라 알 수가 없다 ㅋㅋㅋㅋ

https://nlp.chonbuk.ac.kr/CD/ch06.pdf


하여튼 이런 알고리즘 원리를 이용해서 문장의 구조가 문법적으로 맞으면 파스트리를 생성하는 단계라고 보자.




3. 의미 분석


의미 분석 단계에서는 구문 트리와 심볼 테이블에 있는 정보를 이용하여 

소스 코드가 언어 정의에 의미적으로 부합하는지를 검사한다.


'엄마를 밥을 먹는다' 라는 문장은 문장 구조적으로는 문제가 없다.

명사와 조사 목적어 동사 등 완벽하게 잘 위치해 있다.

하지만 '를' 이라는 문자 하나 때문에 그 의미가 완전하지 못한 상태이다.


이런 식으로 의미 분석 단계에서는 의미적으로 올바르지 않은 코드의 존재 유무를 검사한다.



명령어와 문장을 하나 비교해 보자면.


'엄마는 외계인' 이라는 문장은 의미적으로 틀렸다.

컴파일러는 엄마를 '인간'으로 알고 있기 때문이다.

그래서 '엄마는 외계인은' int a = "코미클" 과도 같은 상황이다.

int 자료형 변수 a에 문자열이 들어갔기 때문이다.

컴파일러는 int에는 정수가 들어갈 수 있는 것으로 인지하고 있는데 

뜬금없이 문자열이 들어오니 오류를 출력하는 것이다.





4. 중간 코드(바이트 코드)


이제 위와 같은 모든 과정이 끝나면 마지막으로 중간 코드를 생성하게 된다.

중간코드는 JVM 이 읽을 수 있는 언어라고 생각하면 된다. JVM에서는 이 중간 코드를 바이트 코드 라고 하는데

JVM은 이 바이트코드를 읽어 들여서 컴퓨터 이해할 수 있는 언어로 변환한다.


참고로 JVM은 자바언어에서만 사용하지 않는다.

대표적으로 스칼라, JRUBY, 코틀린도 JVM 이라는 가상 환경 안에서 놀고 있다.
 
이 4가지 언어들은 무조건 실행하기전에 컴파일 과정에서, 바이트 코드로 번역되는 과정을 가진다.

그래서 인지 모르겠지만, 이 글을 쓴 사람은 Java 프로젝트에 코틀린을 물려서 사용하는 걸 몇 번 본적이 있다고 한다.


그럼 이제 정확히 JVM이 하는 일이 뭔 지 알아 보자.

-> 2.JVM 에서 더 다를 예정



